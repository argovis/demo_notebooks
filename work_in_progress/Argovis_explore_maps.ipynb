{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c88d2fb",
   "metadata": {},
   "source": [
    "# Introduction to Timeseries datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772964c9",
   "metadata": {},
   "source": [
    "> Note: you will be best served by familiarizing yourself with the more basic notebooks _Introduction to Argovis_ and _Intro to Argovis' Grid API_ before following this notebook.\n",
    "\n",
    "The generic point schema used by Argovis for point-like data such as Argo profiles and grids works well for data that can be feasilby captured as documents with unique latitude, longitude, and timestamps. However, when considering higher-resolution datasets, indexing independent documents for each such coordinate triple can dramatically exceed the scale of computing resources the point data above requires; for example, while Argo has roughly 3 million such profile documents to consider at the time of writing, a global, quarter-degree grid measured daily for 30 years (a typical scale for satellite products) would have on the order of *10 billion* such documents. In order to represent, index and serve such high-resolution grids on similar compute infrastructure to the point data, we make a minor modification to the generic point schema to form the *generic timeseries schema*:\n",
    "\n",
    " - Vectors in the ``data`` object represent surface measurements, estimates or flags as an ordered timeseries.\n",
    " - The ``data`` document no longer has a single ``timestamp`` key, as the data within corresponds to many timestamps.\n",
    " - The ``metadata`` or ``data`` document must bear a ``timeseries`` key, which is an ordered list of timestamps corresponding to the times associated with each element in the ``data`` vectors.\n",
    "\n",
    "The observant reader will notice that this is very similar to the gridded products which have a ``levels`` key indicating the model depths for each entry in their ``data`` vectors. All other aspects of the generic schema remain consistent between point and timeseries datasets. In this notebook, we'll illustrate the unique features of a couple of timeseries datasets; for all other details, the reader is encouraged to apply what they learned from other Argovis API examples, as most query filters and behaviors remain identical between point and timeseries datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9b903",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd71ef",
   "metadata": {},
   "source": [
    "In addition to importing a few python packages, make sure to plug in your Argovis API key for API_KEY in the next cell. If you don't have a free Argovis API key yet, get one at https://argovis-keygen.colorado.edu/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f100cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argovisHelpers import helpers as avh\n",
    "\n",
    "from Argovis_tasks_helpers import get_route,list_values_for_parameter_to_api_query,show_variable_names_for_collections\n",
    "\n",
    "API_ROOT='https://argovis-api.colorado.edu/'\n",
    "API_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7729705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a list of collections, please see the Argovis swagger page\n",
    "\n",
    "#### in the following we set parameters to plot different gridded products\n",
    "selection_params = {}\n",
    "#+++ example to use Argo profile data and the glodap gridded product (which provides time mean fields)\n",
    "selection_params['collections']  = ['timeseries/noaasst',\n",
    "                                    'timeseries/copernicussla',\n",
    "                                   'timeseries/ccmpwind',\n",
    "                                   'grids/rg09',\n",
    "                                   'grids/glodap',\n",
    "                                   'grids/kg21']\n",
    "#+++\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336433ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://argovis-api.colorado.edu/timeseries/noaasst/vocabulary?parameter=data\n",
      ">>>>> timeseries/noaasst\n",
      "['sst']\n",
      "https://argovis-api.colorado.edu/timeseries/copernicussla/vocabulary?parameter=data\n",
      ">>>>> timeseries/copernicussla\n",
      "['sla', 'adt', 'ugosa', 'ugos', 'vgosa', 'vgos']\n",
      "https://argovis-api.colorado.edu/timeseries/ccmpwind/vocabulary?parameter=data\n",
      ">>>>> timeseries/ccmpwind\n",
      "['uwnd', 'vwnd', 'ws', 'nobs']\n",
      "https://argovis-api.colorado.edu/grids/rg09/vocabulary?parameter=data\n",
      ">>>>> grids/rg09\n",
      "['rg09_salinity', 'rg09_temperature']\n",
      "https://argovis-api.colorado.edu/grids/glodap/vocabulary?parameter=data\n",
      ">>>>> grids/glodap\n",
      "['Cant', 'Cant_Input_N', 'Cant_Input_mean', 'Cant_Input_std', 'Cant_error', 'Cant_relerr', 'NO3', 'NO3_Input_N', 'NO3_Input_mean', 'NO3_Input_std', 'NO3_error', 'NO3_relerr', 'OmegaA', 'OmegaA_Input_N', 'OmegaA_Input_mean', 'OmegaA_Input_std', 'OmegaA_error', 'OmegaA_relerr', 'OmegaC', 'OmegaC_Input_N', 'OmegaC_Input_mean', 'OmegaC_Input_std', 'OmegaC_error', 'OmegaC_relerr', 'PI_TCO2', 'PI_TCO2_Input_N', 'PI_TCO2_Input_mean', 'PI_TCO2_Input_std', 'PI_TCO2_error', 'PI_TCO2_relerr', 'PO4', 'PO4_Input_N', 'PO4_Input_mean', 'PO4_Input_std', 'PO4_error', 'PO4_relerr', 'TAlk', 'TAlk_Input_N', 'TAlk_Input_mean', 'TAlk_Input_std', 'TAlk_error', 'TAlk_relerr', 'TCO2', 'TCO2_Input_N', 'TCO2_Input_mean', 'TCO2_Input_std', 'TCO2_error', 'TCO2_relerr', 'oxygen', 'oxygen_Input_N', 'oxygen_Input_mean', 'oxygen_Input_std', 'oxygen_error', 'oxygen_relerr', 'pHts25p0', 'pHts25p0_Input_N', 'pHts25p0_Input_mean', 'pHts25p0_Input_std', 'pHts25p0_error', 'pHts25p0_relerr', 'pHtsinsitutp', 'pHtsinsitutp_Input_N', 'pHtsinsitutp_Input_mean', 'pHtsinsitutp_Input_std', 'pHtsinsitutp_error', 'pHtsinsitutp_relerr', 'salinity', 'salinity_Input_N', 'salinity_Input_mean', 'salinity_Input_std', 'salinity_error', 'salinity_relerr', 'silicate', 'silicate_Input_N', 'silicate_Input_mean', 'silicate_Input_std', 'silicate_error', 'silicate_relerr', 'temperature', 'temperature_Input_N', 'temperature_Input_mean', 'temperature_Input_std', 'temperature_error', 'temperature_relerr']\n",
      "https://argovis-api.colorado.edu/grids/kg21/vocabulary?parameter=data\n",
      ">>>>> grids/kg21\n",
      "['kg21_ohc15to300']\n"
     ]
    }
   ],
   "source": [
    "# for each selected collection, we list the variables that are available\n",
    "vars_lists = show_variable_names_for_collections(collections_list=selection_params['collections'],API_KEY=API_KEY,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a93710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the variable of interest for each collection\n",
    "selection_params['varnames']     = ['doxy', 'oxygen']\n",
    "selection_params['varnames_qc']  = [',1', ''] #[',1', ''] # argoqc = 1 is best quality\n",
    "selection_params['varname_title']     = 'Oxygen'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c46ed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> timeseries/noaasst\n",
      "https://argovis-api.colorado.edu/timeseries/meta?id=noaasst\n",
      "Time period available:\n",
      "1989-12-31T00:00:00.000Z\n",
      "2023-01-29T00:00:00.000Z\n",
      "--> timeseries/copernicussla\n",
      "https://argovis-api.colorado.edu/timeseries/meta?id=copernicussla\n",
      "Time period available:\n",
      "1993-01-03T00:00:00.000Z\n",
      "2022-07-24T00:00:00.000Z\n",
      "--> timeseries/ccmpwind\n",
      "https://argovis-api.colorado.edu/timeseries/meta?id=ccmpwind\n",
      "Time period available:\n",
      "1993-01-03T00:00:00.000Z\n",
      "2019-12-29T00:00:00.000Z\n",
      "--> grids/rg09\n",
      "https://argovis-api.colorado.edu/grids/meta?id=rg09\n",
      "Time period available:\n",
      "2004-01-15T00:00:00.000Z\n",
      "2022-05-15T00:00:00.000Z\n",
      "--> grids/glodap\n",
      "https://argovis-api.colorado.edu/grids/meta?id=glodap\n",
      "--> grids/kg21\n",
      "https://argovis-api.colorado.edu/grids/meta?id=kg21\n",
      "Time period available:\n",
      "2005-01-15T00:00:00.000Z\n",
      "2020-12-15T00:00:00.000Z\n"
     ]
    }
   ],
   "source": [
    "# for each collection, we show the time period of interest\n",
    "# (please note that this code will be updated in the near future to leverage upcoming summary documemnts for each collection; at that point, the information of interest will be accessed in the same way for all the collections)\n",
    "for icollection in selection_params['collections']:\n",
    "    metaQuery = {'id': icollection.split('/')[1]}\n",
    "    print('--> '+icollection)\n",
    "    meta = avh.query(icollection.split('/')[0]+'/meta', options=metaQuery, apikey=API_KEY, apiroot=get_route(icollection),verbose=True)\n",
    "    \n",
    "    try:\n",
    "        for imeta in meta:\n",
    "            if 'timeseries' in imeta.keys():\n",
    "                print('Time period available:')\n",
    "                print(imeta['timeseries'][0])\n",
    "                print(imeta['timeseries'][-1])\n",
    "    except:\n",
    "        options = {'box': [[-60,27],[-59, 28]]}\n",
    "        bfr     = avh.query(icollection, options=options, apikey=API_KEY, apiroot=get_route(icollection),verbose=False)\n",
    "        bfr_time= [x['timestamp'] for x in bfr]\n",
    "        print('Time period available:')\n",
    "        print(min(bfr_time))\n",
    "        print(max(bfr_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c29c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (350542196.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    to continue from here\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "to continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e3fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a3e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "790de9e5",
   "metadata": {},
   "source": [
    "# NOAA Sea surface temperature timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01dbe27",
   "metadata": {},
   "source": [
    "Argovis indexes the weekly average sea surface temperature on a 1 degree grid as provided by NOAA via [https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.html](https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.html). Let's start by having a look at the metadata for this collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstMetaQuery = {\n",
    "    'id': 'noaasst' \n",
    "}\n",
    "\n",
    "sstMeta = avh.query('timeseries/meta', options=sstMetaQuery, apikey=API_KEY, apiroot=API_ROOT,verbose=True)\n",
    "print(sstMeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40143992",
   "metadata": {},
   "source": [
    "We can see from the usual `data_info` that this dataset contains one variable called `sst` corresponding to weekly mean sea surface temperature. A feature unique to timeseries datasets is that the metadata document (of which there is one per dataset) contains a `timeseries` key; this lists all the timesteps for all the timeseries in the dataset.\n",
    "\n",
    "Additionally, all metadata documents for data products interpolated to a longitude/latitude grid also include a `lattice` key that describes the structure of the grid in latitude and longitude.\n",
    "\n",
    "> **What does lattice center and spacing mean?** Each product with a regular grid indexed by argovis describes its grid with a centerpoint, which is an arbitrary point on the grid close to [0,0] denoted as [longitude, latitude]. Other grid points are found stepping along by the amount in `lattice.spacing`, denoted as [longitude step, latitude step].\n",
    "\n",
    "We can also have a look at a corresponding data document, ID'ed as `<longitude>_<latitude>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1211545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstQuery = {\n",
    "    'id': '14.5_39.5',\n",
    "    'data': 'sst'\n",
    "}\n",
    "\n",
    "sst = avh.query('timeseries/noaasst', options=sstQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c6aa09",
   "metadata": {},
   "source": [
    "The `data` key here is structured according to `data_info` like all other Argovis datasets; the elements correspond to the timestamps in order as found on the metadata document. Asides from looking at `data_info`, the same vocabulary routes seen in other Argovis data products also exist for timeseries. As always, use `enum` to see the options, and then drill into any one of them individually like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe853ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    'parameter': 'enum'\n",
    "}\n",
    "\n",
    "avh.query('timeseries/noaasst/vocabulary', options=vocab, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88bbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    'parameter': 'data'\n",
    "}\n",
    "\n",
    "avh.query('timeseries/noaasst/vocabulary', options=vocab, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbdcbd",
   "metadata": {},
   "source": [
    "Going back to our data query, if instead we provide a time range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstQuery = {\n",
    "    'id': '14.5_39.5',\n",
    "    'data': 'sst',\n",
    "    'startDate': '1993-01-01T00:00:00Z',\n",
    "    'endDate': '1993-02-01T00:00:00Z'\n",
    "}\n",
    "\n",
    "sst = avh.query('timeseries/noaasst', options=sstQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df981548",
   "metadata": {},
   "source": [
    "we get a `timeseries` key appended to the data document to indicate the timestamps of the filtered timeseries; note this is in close analogy to how levels are filtered in Argovis' representation of Argo grids, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78860914",
   "metadata": {},
   "source": [
    "## Zonal and meridional area-weighted averages for timeseries data\n",
    "\n",
    "Much like gridded data, timeseries data can be arranged to easily compute zonal and meridional averages, with area weighting. Lets start by downloading a year of data for a region in the North Atlantic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstQuery = {\n",
    "  \"startDate\": '2002-01-01T00:00:00Z',\n",
    "  \"endDate\": '2012-01-01T00:00:00Z',\n",
    "  \"polygon\": [[-50,50],[-50,55],[-45,55],[-45,50],[-50,50]],\n",
    "  \"data\": 'sst'\n",
    "}\n",
    "sst = avh.query('timeseries/noaasst', options=sstQuery, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8686d0",
   "metadata": {},
   "source": [
    "> **Temporospatial limits of timeseries queries**: because timeseries documents contain information for every timestep in the series, we currently support queries on only small geographic areas, about 50 square degrees at the equator. However, long time duration queries like the one above are well supported. You can, of course, tile multipl requests to cover an arbitrary region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac4e3b",
   "metadata": {},
   "source": [
    "If we then arrange these data documents into a dataframe with columns for longitude, latitude, timestamp and measurement, we can compute and plot area-weighted meridional and zonal averages with our helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helpers.level_df(sst, \n",
    "                      ['sst', 'longitude', 'latitude'], \n",
    "                      timesteps=sst[0]['timeseries'], \n",
    "                      index=[\"latitude\",\"longitude\",\"timestamp\"]\n",
    "                     )\n",
    "ds = df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_mer = helpers.regional_mean(ds, form='meridional')\n",
    "sst_mer['sst'].plot(y=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_zon = helpers.regional_mean(ds, form='zonal')\n",
    "sst_zon['sst'].plot(y=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d1b6f",
   "metadata": {},
   "source": [
    "# Copernicus sea level anomaly timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ffd7f",
   "metadata": {},
   "source": [
    "Argovis indexes a quarter-degree grid of sea level anomalies and absolute dynamic topologies from [https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-sea-level-global](https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-sea-level-global); note that the original daily data reported at this link has been averaged down to weekly averages with timestamps aligned with the NOAA SST dataset described above, for scale and comparison purposes.\n",
    "\n",
    "Let's again start by looking at the single metadata document for this collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "slaMetaQuery = {\n",
    "    'id': 'copernicussla' \n",
    "}\n",
    "\n",
    "slaMeta = avh.query('timeseries/meta', options=slaMetaQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(slaMeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a08030",
   "metadata": {},
   "source": [
    "Identical in structure to the SST metadata, though this dataset contains two data variables: the sea height anomaly `sla` as compared to the local average sea height over the reference period 1993-2012, and the absolute sea height including this anomaly, `adt`. We can query this dataset much the same as any other timeseries data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "slaQuery = {\n",
    "    'id': '-46.875_35.625',\n",
    "    'data': 'all',\n",
    "    'startDate': '1993-01-01T00:00:00Z',\n",
    "    'endDate': '1993-02-01T00:00:00Z'\n",
    "}\n",
    "\n",
    "sla = avh.query('timeseries/copernicussla', options=slaQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(sla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57023957",
   "metadata": {},
   "source": [
    "Here's an example of making an xarray dataset out of SLA data, similar to the SST example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slaQuery_reg = {\n",
    "  \"startDate\": '2002-01-01T00:00:00Z',\n",
    "  \"endDate\": '2012-01-01T00:00:00Z',\n",
    "  \"polygon\": [[-50,50],[-50,55],[-45,55],[-45,50],[-50,50]],\n",
    "  \"data\": 'sla'\n",
    "}\n",
    "\n",
    "sla_reg = avh.query('timeseries/copernicussla', options=slaQuery_reg, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sla = helpers.level_df(sla_reg, \n",
    "                      ['sla', 'longitude', 'latitude'], \n",
    "                      timesteps=sla_reg[0]['timeseries'], \n",
    "                      index=[\"latitude\",\"longitude\",\"timestamp\"]\n",
    "                     )\n",
    "ds_sla = df_sla.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd974ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sla['sla'][:,:,0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f516471b",
   "metadata": {},
   "source": [
    "# REMSS CCMP wind vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9acf29",
   "metadata": {},
   "source": [
    "Similarly to the sea level anaomaly time series, Argovis indexes a weekly average of the [REMSS CCMP wind vector product](https://www.remss.com/measurements/ccmp/). Have a look at the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08391d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmpMetaQuery = {\n",
    "    'id': 'ccmpwind' \n",
    "}\n",
    "\n",
    "ccmpMeta = avh.query('timeseries/meta', options=ccmpMetaQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(ccmpMeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd38828",
   "metadata": {},
   "source": [
    "Let's find the wind data for the same location and time period as the sea surface heights above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ded00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmpQuery = {\n",
    "    'id': '-46.875_35.625',\n",
    "    'data': 'all',\n",
    "    'startDate': '1993-01-01T00:00:00Z',\n",
    "    'endDate': '1993-02-01T00:00:00Z'\n",
    "}\n",
    "\n",
    "ccmp = avh.query('timeseries/ccmpwind', options=ccmpQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(ccmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c40a3c",
   "metadata": {},
   "source": [
    "We can plot wind speeds in a region and on a date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'startDate': '1993-01-01T00:00:00Z',\n",
    "  'endDate': '1993-02-01T00:00:00Z',\n",
    "  \"polygon\": [[-50,50],[-50,55],[-45,55],[-45,50],[-50,50]],\n",
    "  \"data\": 'all'\n",
    "}\n",
    "\n",
    "wsdata = avh.query('timeseries/ccmpwind', options=params, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helpers.level_df(wsdata, ['ws', 'longitude', 'latitude'], timesteps=wsdata[0]['timeseries'], index=['longitude', 'latitude', 'timestamp'])\n",
    "ds = df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridmap = ds.loc[{\"timestamp\":avh.parsetime('1993-01-10T00:00:00.000Z')}]\n",
    "gridmap['ws'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argovis_demos",
   "language": "python",
   "name": "argovis_demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
